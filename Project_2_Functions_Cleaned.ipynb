{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "\n",
    "# Load image data\n",
    "data_load_1 = sio.loadmat('Proj2FeatVecsSet1.mat')\n",
    "data_load_2 = sio.loadmat('Proj2TargetOutputsSet1.mat')\n",
    "data_set = data_load_1['Proj2FeatVecsSet1']\n",
    "data_target = data_load_2['Proj2TargetOutputsSet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide my target data into nice 1-D classifier\n",
    "number_labels = []\n",
    "for ars in data_target:\n",
    "    if np.all(ars == [1,-1,-1,-1,-1]):\n",
    "        ars = 1\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,1,-1,-1,-1]):\n",
    "        ars = 2\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,1,-1,-1]):\n",
    "        ars = 3\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,-1,1,-1]):\n",
    "        ars = 4\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,-1,-1,1]):\n",
    "        ars = 5\n",
    "        number_labels.append(ars)\n",
    "        \n",
    "number_labels = np.asarray(number_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define how many components we should use and run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(data_set)\n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "eigenvalues = pca.explained_variance_\n",
    "\n",
    "count = 0\n",
    "for var in cum_var:\n",
    "    count += 1\n",
    "    if var >= 0.95:\n",
    "        n_components = count\n",
    "#         answer = \"We need about \"+ str(n_components) + \" components to retain 95% of the variance\"\n",
    "#         print(answer)\n",
    "        break\n",
    "        \n",
    "# plt.figure(1)\n",
    "# plt.plot(cum_var)\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.figure(2)\n",
    "# plt.plot(eigenvalues)\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Eigenvalues')\n",
    "# plt.show()\n",
    "\n",
    "# Minumum Noise Factor --> Similar to PCA but removes noise from bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import rescale\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#Using PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_data = pca.fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Data Folds - Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# #############################################################################\n",
    "# Split into a training set and a test set using a stratified k fold\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    reduced_data, number_labels, test_size=0.20, stratify = number_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data breakdown - For X_train_1 and y_train_1, take sample of 1000 out of 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This can be done nicely with the kfold function\n",
    "X_train_1 = X_train[:1000]\n",
    "X_train_2 = X_train[5000:9999]\n",
    "X_train_3 = X_train[10000:14999]\n",
    "X_train_4 = X_train[15000:20000]\n",
    "y_train_1 = y_train[:1000]\n",
    "y_train_2 = y_train[5000:9999]\n",
    "y_train_3 = y_train[10000:14999]\n",
    "y_train_4 = y_train[15000:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainMyClassifierParameters Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainMyClassifierParameters(Algorithm):\n",
    "    if Algorithm == 'SVM':\n",
    "        Parameters = {\n",
    "            'C' : [0.1],\n",
    "            'gamma' : [0.1]\n",
    "        }\n",
    "    elif Algorithm == 'RVM':\n",
    "        Parameters = {\n",
    "            'alpha' : [1e-06],\n",
    "            'beta' : [1e-06]\n",
    "        }\n",
    "    elif Algorithm == 'GP':\n",
    "        Parameters = {\n",
    "            'length_scale' : [1]             \n",
    "        }\n",
    "    return Parameters, Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainMyClassifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not sure if this is the correct type of function we need\n",
    "def TrainMyClassifier(XEstimate, YEstimate, XValidate, TrainMyClassifierParameters):\n",
    "    from sklearn.svm import SVC\n",
    "    from skrvm import RVC\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    from sklearn.multiclass import OneVsOneClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.gaussian_process.kernels import RBF\n",
    "    from time import time\n",
    "    t0 = time()\n",
    "    # Paramaters should have this shape in order for it to work ==>  Parameters = {'C': [1e3, 1e4, 1e5], 'gamma': [0.001, 0.01, 0.1] }\n",
    "    if TrainMyClassifierParameters[1] == 'SVM':\n",
    "        # ################################################\n",
    "        # Train a SVM classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        param_grid = TrainMyClassifierParameters[0]\n",
    "#         clf = OneVsOneClassifier(GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid))\n",
    "        clf = OneVsOneClassifier(SVC(kernel='rbf', class_weight='balanced'))\n",
    "        clf = clf.fit(XEstimate, YEstimate)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores\n",
    "    elif TrainMyClassifierParameters[1] == 'RVM':\n",
    "        # #############################################################################\n",
    "        # Train a RVM classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        t0 = time()\n",
    "        param_grid = TrainMyClassifierParameters[0]\n",
    "        clf = OneVsOneClassifier(RVC(kernel='rbf',n_iter=1))\n",
    "        clf.fit(XEstimate, YEstimate)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores\n",
    "    elif TrainMyClassifierParameters[1] == 'GP':\n",
    "       # #############################################################################\n",
    "        # Train a GP classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        t0 = time()\n",
    "        param_grid = TrainMyClassifierParameters[0]['length_scale']\n",
    "        k_rbf = 1 * RBF(length_scale=param_grid)\n",
    "        clf = OneVsOneClassifier(GaussianProcessClassifier(kernel = k_rbf))\n",
    "        clf.fit(X_train_1, y_train_1)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores\n",
    "    else:\n",
    "        print(\"Incorrect type of algorithm, please use only one of the supported classifiers SVM, RVM, GP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 0.512s\n"
     ]
    }
   ],
   "source": [
    "test = TrainMyClassifier(X_train_1, y_train_1, X_test,TrainMyClassifierParameters('SVM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyConfusionMatrix Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MyConfusionMatrix(Y,YValidate,ClassNames):\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import pandas as pd\n",
    "    c_r = classification_report(YValidate, Y)\n",
    "    c_m = confusion_matrix(YValidate, Y)\n",
    "    a_s = accuracy_score(YValidate, Y)\n",
    "    # labels = ['One','Two','Three','Four','Five'] - This is the format of the labels\n",
    "    labels = ClassNames\n",
    "    df = pd.DataFrame(c_m, dtype='str', index=labels)\n",
    "    df.columns = ClassNames\n",
    "    return c_m, df, a_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[959,  25,  29,  22,  21],\n",
       "        [ 14, 817,   0,  52,   2],\n",
       "        [ 16,   5, 935,  12,  14],\n",
       "        [  2, 150,  10, 883,  37],\n",
       "        [  9,   3,  26,  31, 926]]),        One  Two Three Four Five\n",
       " One    959   25    29   22   21\n",
       " Two     14  817     0   52    2\n",
       " Three   16    5   935   12   14\n",
       " Four     2  150    10  883   37\n",
       " Five     9    3    26   31  926, 0.90400000000000003)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyConfusionMatrix(y_test, test[0],['One','Two','Three','Four','Five'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyCrossValidate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyCrossValidate(XTrain,YTrain2,Nf,Algorithm): #Why do we use a YTrain with '2' index?\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    dict = {} \n",
    "    \n",
    "    pca = PCA(n_components=9)\n",
    "    reduced_data = pca.fit_transform(XTrain)\n",
    "    #print reduced_data.shape\n",
    "    kf = KFold(n_splits=Nf)\n",
    "    kf.get_n_splits(XTrain)\n",
    "    EstParameters = []\n",
    "    EstConfMatrices = []\n",
    "    ConfMatrix=[]\n",
    "    YTrain = []\n",
    "    YPreds = []\n",
    "    YValids = []\n",
    "    i=0        \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        XEst1 = XTrain[train_index]\n",
    "        YEst1 = YTrain2[train_index]      \n",
    "        XValid = XTrain[test_index]\n",
    "        YValid = YTrain2[test_index]          \n",
    "        XEst = XEst1[:4000]\n",
    "        YEst = YEst1[:4000]\n",
    "        TrainMyClassifierParameters = []\n",
    "        TrainMyClassifierParameters.append({'C': [1e3], 'gamma': [0.001] })\n",
    "        TrainMyClassifierParameters.append(Algorithm)\n",
    "        y_pred1, scores1 = TrainMyClassifier(XEst,YEst,XValid,TrainMyClassifierParameters)\n",
    "        TrainMyClassifierParameters[0] = {'C': [1e4], 'gamma': [0.01]}\n",
    "        y_pred2, scores2 = TrainMyClassifier(XEst,YEst,XValid,TrainMyClassifierParameters)\n",
    "        TrainMyClassifierParameters[0] = {'C': [1e5], 'gamma': [0.1]}\n",
    "        y_pred3, scores3 = TrainMyClassifier(XEst,YEst,XValid,TrainMyClassifierParameters)\n",
    "        if max(scores1,scores2,scores3)==scores1:\n",
    "            y_pred = y_pred1\n",
    "            dict[i]= {'scores':[scores1,scores2,scores3],'C': [1e3], 'gamma': [0.001]}\n",
    "        elif max(scores1,scores2,scores3)==scores2:\n",
    "            y_pred = y_pred2\n",
    "            dict[i]= {'scores':[scores1,scores2,scores3],'C': [1e4], 'gamma': [0.01]}\n",
    "        else:\n",
    "            y_pred = y_pred3  \n",
    "            dict[i]= {'scores':[scores1,scores2,scores3],'C': [1e5], 'gamma': [0.1]}\n",
    "        confMatrix, df, a_s = MyConfusionMatrix(y_pred,YValid,['One','Two','Three','Four','Five'])\n",
    "        EstConfMatrices.append(confMatrix)\n",
    "#         EstParameters.append(params)\n",
    "        YTrain.append(y_pred)\n",
    "        YPreds = np.concatenate((YPreds,y_pred))\n",
    "        YValids = np.concatenate((YValids,YValid))\n",
    "        i=i+1\n",
    "#         y_pred, params = TrainMyClassifier(XEst,YEst,XValid,Algorithm,{'C': [1], 'gamma': [1] })\n",
    "#         confMatrix = MyConfusionMatrix(y_pred,YValid)\n",
    "#         EstConfMatrices.append(confMatrix)\n",
    "#         EstParameters.append(params)\n",
    "#         YTrain.append(y_pred)\n",
    "    ConfMatrix, df, a_s = MyConfusionMatrix(YPreds,YValids,['One','Two','Three','Four','Five'])\n",
    "    np.save(Algorithm+'.npy',dict)\n",
    "    return YTrain,EstParameters,EstConfMatrices,ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 45.897s\n",
      "Fitting the classifier to the training set\n",
      "done in 45.450s\n",
      "Fitting the classifier to the training set\n",
      "done in 48.215s\n",
      "Fitting the classifier to the training set\n",
      "done in 57.116s\n",
      "Fitting the classifier to the training set\n",
      "done in 55.931s\n",
      "Fitting the classifier to the training set\n",
      "done in 49.076s\n",
      "Fitting the classifier to the training set\n",
      "done in 49.007s\n",
      "Fitting the classifier to the training set\n",
      "done in 47.890s\n",
      "Fitting the classifier to the training set\n",
      "done in 49.402s\n",
      "Fitting the classifier to the training set\n",
      "done in 47.682s\n",
      "Fitting the classifier to the training set\n",
      "done in 48.003s\n",
      "Fitting the classifier to the training set\n",
      "done in 46.977s\n",
      "Fitting the classifier to the training set\n",
      "done in 48.770s\n",
      "Fitting the classifier to the training set\n",
      "done in 52.184s\n",
      "Fitting the classifier to the training set\n",
      "done in 49.523s\n",
      "[[3872   48   43   17   20]\n",
      " [  65 3414   28  477   16]\n",
      " [  72   13 3748   43  124]\n",
      " [  45  352   44 3457  102]\n",
      " [  37    8  119  136 3700]]\n"
     ]
    }
   ],
   "source": [
    "YTrain,EstParameters,EstConfMatrices,ConfMatrix = MyCrossValidate(X_train,y_train,5,'RVM')\n",
    "print (ConfMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestMyClassifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestMyClassifier(XTest, Parameters, EstParameters):\n",
    "    # Do similar to trainmyclassifer but with the data from MyCrossValidation\n",
    "    return YTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
